{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xMw-zhrhW0Y",
        "colab_type": "text"
      },
      "source": [
        "Esse colab foi desenvolvido por Alessandra Abreu\n",
        "Entre em contat por alessandra.faria.abreu@gmail.com em caso de dúvidas\n",
        "\n",
        "Auto-Sklearn\n",
        "O auto-sklearn é um kit de ferramentas de aprendizado de máquina automatizado e um substituto para um estimador de aprendizado de scikit. Ele libera um usuário de aprendizado de máquina da seleção de algoritmos e do ajuste de hiperparâmetros. Ele aproveita as vantagens recentes em otimização bayesiana, meta-aprendizado e construção de conjuntos.\n",
        "\n",
        "https://automl.github.io/auto-sklearn/master/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjpGiDnYtpPP",
        "colab_type": "text"
      },
      "source": [
        "# **Importação das bibliotecas**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAIY0BxMNFua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#permite que os gráficos gerados sejam mostrados na mesma janela\n",
        "%matplotlib inline \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets, linear_model \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "#define o estilo dos gráficos , \"ggplot\" é um estilo popular em R\n",
        "plt.style.use('ggplot') \n",
        "\n",
        "# Algumas configurações para o matplotlib.\n",
        "from IPython.core.pylabtools import figsize\n",
        "figsize(12, 8)\n",
        "sns.set()\n",
        "from scipy import stats\n",
        "%%time\n",
        "import sklearn.datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import autosklearn.classification\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ9TbxN5MAbn",
        "colab_type": "text"
      },
      "source": [
        "CASO O autosklearn NÃO SEJA IMPORTADO EXECUTE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXAmnQiZMR7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#O notebook foi criado com base no scikit-learn 0.19.2, smac 0.8.0 e auto-sklearn 0.5.1.\n",
        "\n",
        "!apt-get install swig -y\n",
        "!pip install Cython numpy\n",
        "\n",
        "# sometimes you have to run the next command twice on colab\n",
        "# I haven't figured out why\n",
        "!pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g033l_vEMZj4",
        "colab_type": "text"
      },
      "source": [
        "IMPORTANDO A BASE DE DADOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7fXew0umxAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df = pd.read_csv(\"../src/estaticos_market.csv\")\n",
        "#df = df.drop(['Unnamed: 0'], axis=1)\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "link =  \"--" #LINK DA BASE ORIGINAL\n"
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Original_Data_original_CSV.csv')  \n",
        "\n",
        "df = pd.read_csv('Original_Data_original_CSV.csv', sep=';', decimal='.', encoding = \"UTF-8\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX8rVciDOggm",
        "colab_type": "text"
      },
      "source": [
        "VERIFICANDO A IMPORTAÇÃO DA BASE DE DADOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxm-RxVhZDi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a501d274-3bb7-4e40-d531-3ade746cd6e1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v0001</th>\n",
              "      <th>v0002</th>\n",
              "      <th>v0003</th>\n",
              "      <th>v0004</th>\n",
              "      <th>v0005</th>\n",
              "      <th>v0006</th>\n",
              "      <th>v0007</th>\n",
              "      <th>v0008</th>\n",
              "      <th>v0009</th>\n",
              "      <th>v0010</th>\n",
              "      <th>v0011</th>\n",
              "      <th>v0012</th>\n",
              "      <th>v0013</th>\n",
              "      <th>v0014</th>\n",
              "      <th>v0015</th>\n",
              "      <th>v0016</th>\n",
              "      <th>v0017</th>\n",
              "      <th>v0018</th>\n",
              "      <th>v0019</th>\n",
              "      <th>v0020</th>\n",
              "      <th>v0021</th>\n",
              "      <th>v0022</th>\n",
              "      <th>v0023</th>\n",
              "      <th>v0024</th>\n",
              "      <th>v0025</th>\n",
              "      <th>v0026</th>\n",
              "      <th>v0027</th>\n",
              "      <th>v0028</th>\n",
              "      <th>v0029</th>\n",
              "      <th>v0030</th>\n",
              "      <th>v0031</th>\n",
              "      <th>v0032</th>\n",
              "      <th>v0033</th>\n",
              "      <th>v0034</th>\n",
              "      <th>v0035</th>\n",
              "      <th>v0036</th>\n",
              "      <th>v0037</th>\n",
              "      <th>v0038</th>\n",
              "      <th>v0039</th>\n",
              "      <th>v0040</th>\n",
              "      <th>...</th>\n",
              "      <th>v2947</th>\n",
              "      <th>v2948</th>\n",
              "      <th>v2949</th>\n",
              "      <th>v2950</th>\n",
              "      <th>v2951</th>\n",
              "      <th>v2952</th>\n",
              "      <th>v2953</th>\n",
              "      <th>v2954</th>\n",
              "      <th>v2955</th>\n",
              "      <th>v2956</th>\n",
              "      <th>v2957</th>\n",
              "      <th>v2958</th>\n",
              "      <th>v2959</th>\n",
              "      <th>v2960</th>\n",
              "      <th>v2961</th>\n",
              "      <th>v2962</th>\n",
              "      <th>v2963</th>\n",
              "      <th>v2964</th>\n",
              "      <th>v2965</th>\n",
              "      <th>v2966</th>\n",
              "      <th>v2967</th>\n",
              "      <th>v2968</th>\n",
              "      <th>v2969</th>\n",
              "      <th>v2970</th>\n",
              "      <th>v2971</th>\n",
              "      <th>v2972</th>\n",
              "      <th>v2973</th>\n",
              "      <th>v2974</th>\n",
              "      <th>v2975</th>\n",
              "      <th>v2976</th>\n",
              "      <th>v2977</th>\n",
              "      <th>v2978</th>\n",
              "      <th>v2979</th>\n",
              "      <th>v2980</th>\n",
              "      <th>v2981</th>\n",
              "      <th>v2982</th>\n",
              "      <th>v2983</th>\n",
              "      <th>v2984</th>\n",
              "      <th>PriorDrugUse</th>\n",
              "      <th>fPerDisorders</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>250</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>7</td>\n",
              "      <td>1997</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>99999999</td>\n",
              "      <td>2003</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>1,0531</td>\n",
              "      <td>1,0120</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>90,5009</td>\n",
              "      <td>91,5869</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>99999999</td>\n",
              "      <td>9999</td>\n",
              "      <td>999999</td>\n",
              "      <td>999999</td>\n",
              "      <td>100000,0000</td>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>2001</td>\n",
              "      <td>0</td>\n",
              "      <td>2001</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "      <td>1,00</td>\n",
              "      <td>0,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>230</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>2000</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>12</td>\n",
              "      <td>2000</td>\n",
              "      <td>99999999</td>\n",
              "      <td>2003</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>1,0642</td>\n",
              "      <td>1,0120</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>91,4548</td>\n",
              "      <td>92,5523</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>99999999</td>\n",
              "      <td>9999</td>\n",
              "      <td>999999</td>\n",
              "      <td>999999</td>\n",
              "      <td>100000,0000</td>\n",
              "      <td>6</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "      <td>1,00</td>\n",
              "      <td>0,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>175</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>4</td>\n",
              "      <td>2003</td>\n",
              "      <td>99999999</td>\n",
              "      <td>2003</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>1,0610</td>\n",
              "      <td>1,0120</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>91,1798</td>\n",
              "      <td>92,2740</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>99999999</td>\n",
              "      <td>9999</td>\n",
              "      <td>999999</td>\n",
              "      <td>999999</td>\n",
              "      <td>100000,0000</td>\n",
              "      <td>4</td>\n",
              "      <td>2003</td>\n",
              "      <td>0</td>\n",
              "      <td>2003</td>\n",
              "      <td>0</td>\n",
              "      <td>2003</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "      <td>0,00</td>\n",
              "      <td>1,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>190</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>2001</td>\n",
              "      <td>99</td>\n",
              "      <td>1991</td>\n",
              "      <td>7</td>\n",
              "      <td>2000</td>\n",
              "      <td>99999999</td>\n",
              "      <td>2003</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>1,0546</td>\n",
              "      <td>1,0120</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>90,6298</td>\n",
              "      <td>91,7174</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>99999999</td>\n",
              "      <td>9999</td>\n",
              "      <td>999999</td>\n",
              "      <td>999999</td>\n",
              "      <td>100000,0000</td>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>2001</td>\n",
              "      <td>0</td>\n",
              "      <td>2001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>1,00</td>\n",
              "      <td>1,00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>160</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>1998</td>\n",
              "      <td>99</td>\n",
              "      <td>9999</td>\n",
              "      <td>3</td>\n",
              "      <td>1997</td>\n",
              "      <td>99999999</td>\n",
              "      <td>2003</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>1,0567</td>\n",
              "      <td>1,0120</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>85,9376</td>\n",
              "      <td>90,8103</td>\n",
              "      <td>91,9000</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>99999999</td>\n",
              "      <td>9999</td>\n",
              "      <td>999999</td>\n",
              "      <td>999999</td>\n",
              "      <td>100000,0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1997</td>\n",
              "      <td>0</td>\n",
              "      <td>1998</td>\n",
              "      <td>0</td>\n",
              "      <td>1998</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>1,00</td>\n",
              "      <td>0,00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2986 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   v0001  v0002  v0003  v0004  ...  v2983  v2984  PriorDrugUse  fPerDisorders\n",
              "0      1     10    201      1  ...      2    101          1,00           0,00\n",
              "1      2     10    201      1  ...      2    101          1,00           0,00\n",
              "2      3     10    201      1  ...      2    101          0,00           1,00\n",
              "3      4     10    201      1  ...      1    101          1,00           1,00\n",
              "4      5     10    201      1  ...      1    101          1,00           0,00\n",
              "\n",
              "[5 rows x 2986 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OdDLihTG1SN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "951ba730-d3ac-4fda-8453-842ce3d71356"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14499, 2986)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoVlIeMKMjHh",
        "colab_type": "text"
      },
      "source": [
        "EXPLORANDO ALGUNS DADOS DA BASE DE DADOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ZcChd9uvPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "da7bf686-e88e-4b4c-83c5-4f79a127c27d"
      },
      "source": [
        "def resumetable(df):\n",
        "    print(f\"Dataset Shape: {df.shape}\")\n",
        "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
        "    summary = summary.reset_index()\n",
        "    summary['Name'] = summary['index']\n",
        "    summary = summary[['Name','dtypes']]\n",
        "    summary['Missing'] = df.isnull().sum().values    \n",
        "    summary['Uniques'] = df.nunique().values\n",
        "    summary['First Value'] = df.loc[0].values\n",
        "    summary['Second Value'] = df.loc[1].values\n",
        "    summary['Third Value'] = df.loc[2].values\n",
        "\n",
        "    for name in summary['Name'].value_counts().index:\n",
        "        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n",
        "\n",
        "    return summary\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "\n",
        "resumetable(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Shape: (14499, 2986)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>dtypes</th>\n",
              "      <th>Missing</th>\n",
              "      <th>Uniques</th>\n",
              "      <th>First Value</th>\n",
              "      <th>Second Value</th>\n",
              "      <th>Third Value</th>\n",
              "      <th>Entropy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v0001</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>14499</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>13.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v0002</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v0003</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>201</td>\n",
              "      <td>201</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v0004</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v0005</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2981</th>\n",
              "      <td>v2982</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2982</th>\n",
              "      <td>v2983</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2983</th>\n",
              "      <td>v2984</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>287</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>8.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2984</th>\n",
              "      <td>PriorDrugUse</td>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1,00</td>\n",
              "      <td>1,00</td>\n",
              "      <td>0,00</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2985</th>\n",
              "      <td>fPerDisorders</td>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0,00</td>\n",
              "      <td>0,00</td>\n",
              "      <td>1,00</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2986 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Name  dtypes  Missing  ...  Second Value Third Value Entropy\n",
              "0             v0001   int64        0  ...             2           3   13.82\n",
              "1             v0002   int64        0  ...            10          10    0.10\n",
              "2             v0003   int64        0  ...           201         201    0.10\n",
              "3             v0004   int64        0  ...             1           1    0.73\n",
              "4             v0005   int64        0  ...             1           1    0.73\n",
              "...             ...     ...      ...  ...           ...         ...     ...\n",
              "2981          v2982   int64        0  ...             2           2    1.84\n",
              "2982          v2983   int64        0  ...             2           2    1.75\n",
              "2983          v2984   int64        0  ...           101         101    8.11\n",
              "2984   PriorDrugUse  object        0  ...          1,00        0,00    0.65\n",
              "2985  fPerDisorders  object        0  ...          0,00        1,00    0.88\n",
              "\n",
              "[2986 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPC9m_R4i5do",
        "colab_type": "text"
      },
      "source": [
        "# EXECUTANDO O MODELO\n",
        "\n",
        "**ATENÇÃO**: NO COLAB EXECUÇÕES MAIORES QUE 10 HORAS GERAM TIME-OUT!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Q6qXGENgSp",
        "colab_type": "text"
      },
      "source": [
        "SEPARANDO O TREINO, O TESTE E A VALIDAÇÃO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ypsXM3hNMqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "df.fillna(0, inplace=True)\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop('v2517',\n",
        "                                                    axis=1),\n",
        "                                                    df['v2517'],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbeTsZhHcgCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "b9db1abe-aae9-408f-b619-68b36810a353"
      },
      "source": [
        "\n",
        "# configure auto-sklearn\n",
        "automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "          time_left_for_this_task=3600, # execute o auto-sklearn por no máximo x segundos\n",
        "          per_run_time_limit=600, #, gastar no máximo Y segundos para cada modelo de treinamento\n",
        "           include_preprocessors=None\n",
        "          #include_estimators=[\"adaboost\"]  #Caso queira que ele execute somente um tipo de modelo\n",
        "          )\n",
        "\n",
        "\n",
        "# train model(s)\n",
        "automl.fit(x_train, y_train)\n",
        "\n",
        "# evaluate\n",
        "y_hat = automl.predict(x_test)\n",
        "test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)\n",
        "test_report = sklearn.metrics.classification_report(y_test, y_hat)\n",
        "test_matrix = sklearn.metrics.confusion_matrix(y_test, y_hat)\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(\"Test Accuracy score {0}\".format(test_acc))\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(\"Test Report score {0}\".format(test_report))\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(\"Test Confusion Matrix {0}\".format(test_matrix))\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(automl.sprint_statistics())\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(automl.show_models())\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(automl.get_models_with_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------\n",
            "Test Accuracy score 0.500919540229885\n",
            "-------------------------------------------------------------------------\n",
            "Test Report score               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      1.00      0.67      2179\n",
            "           2       0.00      0.00      0.00      2085\n",
            "           7       0.00      0.00      0.00         9\n",
            "           8       0.00      0.00      0.00        26\n",
            "           9       0.00      0.00      0.00        51\n",
            "\n",
            "    accuracy                           0.50      4350\n",
            "   macro avg       0.10      0.20      0.13      4350\n",
            "weighted avg       0.25      0.50      0.33      4350\n",
            "\n",
            "-------------------------------------------------------------------------\n",
            "Test Confusion Matrix [[2179    0    0    0    0]\n",
            " [2085    0    0    0    0]\n",
            " [   9    0    0    0    0]\n",
            " [  26    0    0    0    0]\n",
            " [  51    0    0    0    0]]\n",
            "-------------------------------------------------------------------------\n",
            "auto-sklearn results:\n",
            "  Dataset name: 4c6f9122fdfba7d9141014437cfae6ab\n",
            "  Metric: accuracy\n",
            "  Number of target algorithm runs: 817\n",
            "  Number of successful target algorithm runs: 0\n",
            "  Number of crashed target algorithm runs: 0\n",
            "  Number of target algorithms that exceeded the time limit: 0\n",
            "  Number of target algorithms that exceeded the memory limit: 817\n",
            "\n",
            "-------------------------------------------------------------------------\n",
            "[(1.000000, MyDummyClassifier(configuration=1, init_params=None, random_state=None)),\n",
            "]\n",
            "-------------------------------------------------------------------------\n",
            "[(1.0, MyDummyClassifier(configuration=1, init_params=None, random_state=None))]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFHXbD9_NE8K",
        "colab_type": "text"
      },
      "source": [
        "RESULTADOS COLETADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s372LZ8uhMwm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Teste 1**\n",
        "\n",
        "1.   60 minutos de execução\n",
        "2.   600 segundos por modelo\n",
        "Test Accuracy score 0.7116520917040888\n",
        " Metric: accuracy\n",
        " \n",
        "  Best validation score: 0.713321\n",
        " \n",
        "  Number of target algorithm runs: 150\n",
        " \n",
        "  Number of successful target algorithm runs: 128\n",
        " \n",
        "  Number of crashed target algorithm runs: 1\n",
        " \n",
        "  Number of target algorithms that exceeded the time limit: 1\n",
        " \n",
        "  Number of target algorithms that exceeded the memory limit: 20\n",
        "\n",
        "\n",
        "```\n",
        "(\n",
        "   0.100000,\n",
        "   SimpleClassificationPipeline(   {\n",
        "      'balancing:strategy':'none',\n",
        "      'categorical_encoding:__choice__':'one_hot_encoding',\n",
        "      'classifier:__choice__':'liblinear_svc',\n",
        "      'imputation:strategy':'median',\n",
        "      'preprocessor:__choice__':'extra_trees_preproc_for_classification',\n",
        "      'rescaling:__choice__':'minmax',\n",
        "      'categorical_encoding:one_hot_encoding:use_minimum_fraction':'False',\n",
        "      'classifier:liblinear_svc:C':758.0503113370363,\n",
        "      'classifier:liblinear_svc:dual':'False',\n",
        "      'classifier:liblinear_svc:fit_intercept':'True',\n",
        "      'classifier:liblinear_svc:intercept_scaling':1,\n",
        "      'classifier:liblinear_svc:loss':'squared_hinge',\n",
        "      'classifier:liblinear_svc:multi_class':'ovr',\n",
        "      'classifier:liblinear_svc:penalty':'l2',\n",
        "      'classifier:liblinear_svc:tol':5.1083937738328576e-05,\n",
        "      'preprocessor:extra_trees_preproc_for_classification:bootstrap':'False',\n",
        "      'preprocessor:extra_trees_preproc_for_classification:criterion':'entropy',\n",
        "      'preprocessor:extra_trees_preproc_for_classification:max_depth':'None',\n",
        "      'preprocessor:extra_trees_preproc_for_classification:max_features':0.8484703600145612,\n",
        "      'preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes':'None',\n",
        "      'preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease':0.0,\n",
        "      'preprocessor:extra_trees_preproc_for_classification:min_samples_leaf':3,\n",
        "      'preprocessor:extra_trees_preproc_for_classification:min_samples_split':15,\n",
        "      'preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf':0.0,\n",
        "      'preprocessor:extra_trees_preproc_for_classification:n_estimators':100\n",
        "   },\n",
        "   dataset_properties=   {\n",
        "      'task':1,\n",
        "      'sparse':False,\n",
        "      'multilabel':False,\n",
        "      'multiclass':False,\n",
        "      'target_type':'classification',\n",
        "      'signed':False\n",
        "   }\n",
        "))\n",
        "```\n",
        "\n",
        "\n",
        "**Teste 2**\n",
        "\n",
        "1.   21600 minutos de execução\n",
        "2.   3600 segundos por modelo\n",
        "Test Accuracy score 0.7102339872370598\n",
        "\n",
        "auto-sklearn results:\n",
        "  \n",
        "  Dataset name: e78bcd990d61d13e2fd97daa29ba0d48\n",
        "  \n",
        "  Metric: accuracy\n",
        "  \n",
        "  Best validation score: 0.715777\n",
        "  \n",
        "  Number of target algorithm runs: 325\n",
        "  \n",
        "  Number of successful target algorithm runs: 287\n",
        "  \n",
        "  Number of crashed target algorithm runs: 4\n",
        "  \n",
        "  Number of target algorithms that exceeded the time limit: 3\n",
        "  \n",
        "  Number of target algorithms that exceeded the memory limit: 31\n",
        "\n",
        "```\n",
        "[\n",
        "   (\n",
        "      0.180000,\n",
        "      SimpleClassificationPipeline(      {\n",
        "         'balancing:strategy':'weighting',\n",
        "         'categorical_encoding:__choice__':'one_hot_encoding',\n",
        "         'classifier:__choice__':'gradient_boosting',\n",
        "         'imputation:strategy':'median',\n",
        "         'preprocessor:__choice__':'select_percentile_classification',\n",
        "         'rescaling:__choice__':'standardize',\n",
        "         'categorical_encoding:one_hot_encoding:use_minimum_fraction':'False',\n",
        "         'classifier:gradient_boosting:early_stop':'off',\n",
        "         'classifier:gradient_boosting:l2_regularization':1.5968236987108011e-06,\n",
        "         'classifier:gradient_boosting:learning_rate':0.01881073023316283,\n",
        "         'classifier:gradient_boosting:loss':'auto',\n",
        "         'classifier:gradient_boosting:max_bins':256,\n",
        "         'classifier:gradient_boosting:max_depth':'None',\n",
        "         'classifier:gradient_boosting:max_iter':443,\n",
        "         'classifier:gradient_boosting:max_leaf_nodes':44,\n",
        "         'classifier:gradient_boosting:min_samples_leaf':1,\n",
        "         'classifier:gradient_boosting:scoring':'loss',\n",
        "         'classifier:gradient_boosting:tol':1e-07,\n",
        "         'preprocessor:select_percentile_classification:percentile':89.96031925503816,\n",
        "         'preprocessor:select_percentile_classification:score_func':'f_classif'\n",
        "      },\n",
        "      dataset_properties=      {\n",
        "         'task':1,\n",
        "         'sparse':False,\n",
        "         'multilabel':False,\n",
        "         'multiclass':False,\n",
        "         'target_type':'classification',\n",
        "         'signed':False\n",
        "      }      )),\n",
        "\n",
        "```\n",
        "\n",
        "Teste 3\n",
        "\n",
        "1.   6 horas de execução\n",
        "2.   3600 segundos por modelo\n",
        "3.   SVM\n",
        "\n",
        "Test Accuracy score 0.6986528007563224\n",
        "\n",
        "Test Report score               precision    recall  f1-score   support\n",
        "\n",
        "           1       0.74      0.62      0.68      2155\n",
        "           2       0.66      0.78      0.72      2076\n",
        "    accuracy                           0.70      4231\n",
        "   macro avg       0.70      0.70      0.70      4231\n",
        "weighted avg       0.71      0.70      0.70      4231\n",
        "\n",
        "Test Confusion Matrix [[1338  817]\n",
        " [ 458 1618]]\n",
        "\n",
        "auto-sklearn results:\n",
        " \n",
        "  Dataset name: e78bcd990d61d13e2fd97daa29ba0d48\n",
        " \n",
        "  Metric: accuracy\n",
        " \n",
        "  Best validation score: 0.705648\n",
        " \n",
        "  Number of target algorithm runs: 153\n",
        " \n",
        "  Number of successful target algorithm runs: 139\n",
        " \n",
        "  Number of crashed target algorithm runs: 5\n",
        " \n",
        "  Number of target algorithms that exceeded the time limit: 2\n",
        " \n",
        "  Number of target algorithms that exceeded the memory limit: 7\n",
        "\n",
        "\n",
        "```\n",
        "[\n",
        "   (\n",
        "      0.140000,\n",
        "      \"SimpleClassificationPipeline(\"      {\n",
        "         \"balancing:strategy\":\"weighting\",\n",
        "         \"categorical_encoding:__choice__\":\"one_hot_encoding\",\n",
        "         \"classifier:__choice__\":\"libsvm_svc\",\n",
        "         \"imputation:strategy\":\"mean\",\n",
        "         \"preprocessor:__choice__\":\"extra_trees_preproc_for_classification\",\n",
        "         \"rescaling:__choice__\":\"quantile_transformer\",\n",
        "         \"categorical_encoding:one_hot_encoding:use_minimum_fraction\":\"False\",\n",
        "         \"classifier:libsvm_svc:C\":4000.0743582536884,\n",
        "         \"classifier:libsvm_svc:gamma\":4.712396717636236e-05,\n",
        "         \"classifier:libsvm_svc:kernel\":\"poly\",\n",
        "         \"classifier:libsvm_svc:max_iter\":-1,\n",
        "         \"classifier:libsvm_svc:shrinking\":\"True\",\n",
        "         \"classifier:libsvm_svc:tol\":0.04095860125956853,\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:bootstrap\":\"True\",\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:criterion\":\"gini\",\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:max_depth\":\"None\",\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:max_features\":0.11502075457665162,\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes\":\"None\",\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease\":0.0,\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:min_samples_leaf\":14,\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:min_samples_split\":20,\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf\":0.0,\n",
        "         \"preprocessor:extra_trees_preproc_for_classification:n_estimators\":100,\n",
        "         \"rescaling:quantile_transformer:n_quantiles\":1521,\n",
        "         \"rescaling:quantile_transformer:output_distribution\":\"uniform\",\n",
        "         \"classifier:libsvm_svc:coef0\":-0.0769821248281255,\n",
        "         \"classifier:libsvm_svc:degree\":3\n",
        "      },\n",
        "      \"dataset_properties=\"      {\n",
        "         \"task\":1,\n",
        "         \"sparse\":False,\n",
        "         \"multilabel\":False,\n",
        "         \"multiclass\":False,\n",
        "         \"target_type\":\"classification\",\n",
        "         \"signed\":False\n",
        "      }\n",
        "   ))\n",
        "```"
      ]
    }
  ]
}
